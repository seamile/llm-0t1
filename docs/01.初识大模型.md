# 一、初识大模型

![LLM](assets/llm-brain.jpg)

2020 年，随着 ChatGPT 3 横空出世，“大模型”这一概念迅速引爆科技圈，进入公众视野，成为全民热议的话题。

## 1. 什么是大模型？

在 AI 领域我们常说的 “大模型” 指的是 “大语言模型” (英文：Large Language Model，常缩写为 LLM)。它是一种在自然语言处理领域采用超大规模参数和海量数据训练而成的深度神经网络模型。

大语言模型最初的设计目的是为了提高模型的表达能力和预测性能，它本质上只是在预测句子中的下一个单词是什么。但经过足够数据量的训练后人们发现这种语言模型可以捕获人类语言的句法和语义，并且能够在训练期间“记住”大量事实。这赋予了大模型更强大的能力，相较于传统的机器学习它能够处理更加复杂的数据和任务。

传统机器学习模型的参数数量通常在百万级到千万级，而大模型则往往拥有数十亿甚至数千亿个参数。为了获得如此大规模的参数，需要利用互联网中海量的文本、图像、视频等非结构化数据来进行预训练，数据集往往高达数十 TB 甚至数百 TB 的规模。
<div align="center"><img alt="machine_learning" src="/assets/machine_learning.png" width="85%" /></div>


## 2. 大模型的前世今生

### 2.1 早期阶段：统计语言模型

大模型的发展历史可以追溯到20世纪90年代。在深度学习兴起之前，自然语言处理主要依赖于统计学方法。N-gram 模型是这一时期常用的语言模型，通过计算词序列的概率来预测下一个词。然而，统计语言模型在处理长距离依赖和稀疏数据方面表现较差。

<div align="center"><img alt="N-gram" src="/assets/N-gram.webp" width="85%" /></div>

2003 年，深度学习领域最有影响力的先驱之一 Bengio 提出了第一个神经语言模型，将词嵌入（Word Embedding）引入到语言建模中。这一模型利用神经网络来捕捉词之间的关系，提高了语言模型的性能。

### 2.2 深度学习阶段

2010 年代初，循环神经网络（RNN）和长短期记忆网络（LSTM）开始应用于语言模型。这些模型能够处理变长序列数据，并捕捉长距离依赖，但由于梯度消失问题，其性能受到一定限制。

2013 年，Google 的 Tomas Mikolov 等人提出了著名的 [Word2vec 模型](https://arxiv.org/abs/1301.3781)。这一模型基于大规模语料库训练的单词嵌入，它使得词汇的连续向量表征成为可能。Word2vec 有效解决了 N-gram 模型中 "curse of dimensionality" 的瓶颈。

<div align="center"><img alt="Word2vec" src="/assets/Word2vec.webp" width="85%" /></div>

2014 年，Ilya Sutskever 与谷歌研究员 Oriol Vinyals 和 Quoc Le 一起提出了 [Seq2Seq 模型](https://arxiv.org/abs/1409.3215)，并将之用于机器翻译。随后，Bahdanau 等人引入了注意力机制，解决了长序列翻译中的信息压缩问题，大大提升了模型性能。

<div align="center"><img alt="Seq2Seq" src="/assets/seq2seq.png" width="85%" /></div>

### 2.3 Transformer 架构的引入

前期的这些探索，有成功又失败，它们共同奠定了大语言模型的技术基石。

2017 年，由 Ashish Vaswani 等人撰写的论文[《Attention Is All You Need》](https://arxiv.org/abs/1706.03762)中首次介绍了 Transformer 模型。这篇论文由 Google 的团队发表，它提出了一种完全基于注意力机制的全新架构，而不再依赖于循环神经网络（RNN）或卷积神经网络（CNN），这种模型能够高效并行地处理序列数据，极大提高了模型的训练效率和效果。

Transformer 是一项重大突破，它的发布标志着自然语言处理的进入了一个全新阶段。

<div align="center"><img alt="Transformer" src="/assets/transformer.png" width="600" /></div>

2018 年 6 月，OpenAI 发布了首个基于 Transformer 架构的 GPT（Generative Pre-trained Transformer）模型，该模型拥有 1.17 亿的参数量，它展示了预训练和微调（fine-tuning）在语言模型中的巨大潜力。GPT 模型通过大规模预训练，然后在特定任务上进行微调，实现了卓越的性能。

同一年 10 月，Google 发布了 BERT（Bidirectional Encoder Representations from Transformers）模型，该模型同样基于 Transformer 并采用双向编码器架构，能够同时考虑上下文信息。BERT 在多个 NLP 基准任务上取得了前所未有的高分。

![BERT-and-GPT](assets/bert-and-gpt.png)

2019 年，OpenAI 发布了 GPT-2 模型，具有 15 亿参数，展示了出色的自然语言文本的生成能力。2020 年，OpenAI 进一步发布了 GPT-3 模型，用来训练的语料库积累了 8 年，涵盖了几乎所有可用的互联网数据源，其参数量达到了惊人的 1750 亿。

GPT-3.0 在多种语言任务上表现卓越，还展现出了一些在较小模型中未曾观察到的能力，比如更好的语言理解、更复杂的任务处理能力、令人惊叹的涌现能力、以及在零样本和少样本学习中的出色表现。GPT-3.0 模型展现了使用超大规模语料库进行预训练对语言理解和生成任务的价值，它是 GPT 系列中迄今为止最著名的版本，它促成了当前大语言模型百花齐放的局面。

![LLM进化树](assets/llm-models-tree.jpg)

在随后的研究中，全球众多公司、科研机构纷纷推出了更大规模的模型，相关的算法被不断改进，大模型的能力被充分挖掘，应用场景也不断拓展。研究人员开始探索将多种数据类型（如文本、图像、音频等）结合在一起的大模型。例如，OpenAI 的 CLIP 模型、DALL-E 模型、Sora 模型，将文本、图像、视频结合，展示了强大的跨模态生成和理解能力。


## 3. 大模型能帮我们做什么？

### 3.1 大模型的能力

与传统的专门为某一类任务设计的模型不同，大模型在预训练阶段习得了广泛的知识。同时，得益于 Transformer 架构和自注意力机制，使得大模型能够捕捉到文本中的复杂关系。这些技术使大模型具有了很强的通用性、泛化能力、以及涌现能力，可以应用于多种任务，比如：文章创作、翻译、编程等等。

下面是一些常见的大模型应用场景：

- 文本生成与写作

    大模型天生就是用来生成文字的，它可以帮助我们进行各种写作任务。无论是编写文案、邮件，还是撰写论文、报告、演讲稿，大模型都能轻松完成。它们不仅能够模仿人类的写作风格，还能根据输入的提示生成有创意的文字，比如小说、诗歌、剧本等等。

- 问答和信息检索

    搜索引擎是我们如今最主要的获取知识和信息的方式之一，但是对于某些问题的搜索结果往往不尽如人意。

    而大模型在预训练时习得了大量的知识，我们可以让它充当智能助手，回答各种问题。还可以让它和搜索引擎结合，提取结果中的关键信息并进行总结，构建出出一种可以直达结果的搜索引擎，比如：[秘塔搜索](https://metaso.cn/)、[DevvAI](https://devv.ai/zh)。

    虽然大模型很强大，但是在处理一些对准确性要求比较高的内容时，要特别注意大模型的“幻觉问题”。

- 翻译与语言处理

    大模型能够理解多种语言的语言的含义，能够将文本从一种语言翻译成另一种语言，生成符合语法和上下文情境的文本，进行自然流畅的对话。

    这对于跨国交流和多语言环境中的工作非常有帮助。一些开发者甚至利用大模型开发出了用来进行英语学习类的软件，而且效果不错。

- 教育与学习

    在教育领域，大模型可以充当智能导师，学生向模型提问，可以获得详细的解答。大模型还能根据学生的学习状况，提供定制化的学习辅导，推荐适合的学习材料。

    对于已经进入职场人士，可以借助大模型来快速学习，从大量文档中找到关键的知识点，帮助自己提升技能。还可以让大模型进行模拟面试，从容应对面试官的各种刁难。

- 辅助决策与数据分析

    通过处理大量数据，大模型可以生成报告、预测趋势，并提供决策建议。这对于企业和个人进行数据分析和决策时很有帮助。

    在金融市场，甚至可以让大模型分析股票的变化趋势，协助投资者做出更明智的决策。

- 客户服务与交互

    大模型能够以聊天机器人的形式接替大量的客服工作，提供即时的客户支持和信息查询服务。它能够理解用户的问题，提供准确和及时的回答，提高客户满意度。

- 创意与设计

    大模型还可以帮助设计师和艺术家实现其创意。它们可以根据描述生成图像或设计草图，按照设定的风格生成音乐作品，或者撰写视频内容脚本和分镜头脚本。这种能力使大模型成为创意产业中的得力助手。

- 自动化任务

    大模型可以按照我们设定好的工作流程自动化处理各种重复性任务。例如，让它自动按照数据提取、清洗、整理、分析的流程进行数据处理，提高工作效率。这种自动化能力在许多行业中都具有重要意义。

- 编程与技术支持

    大模型在编程领域同样表现出色。它们可以帮助程序员编写代码、调试错误、生成文档、编写测试用例，甚至能够根据需求自动生成完整的程序或网站。这方面最典型的应用就是 GitHub 的 [Copilot](https://github.com/features/copilot)。

    对于学习编程的新手，大模型可以提供实时的指导和解答，帮助他们快速掌握编程技能。

大模型凭借其强大的语言处理能力，正在改变我们的工作和生活方式。上面这些仅仅是一些比较常见的应用场景，随着技术的不断进步以及我们的深入使用，相信还会有更多的场景会被发现。大模型的应用前景将会更加广阔。

### 3.2 大模型的不足

虽然大模型在许多领域展现了强大的能力，但它们也有局限性和无法胜任的任务，了解这些限制对于正确使用大模型至关重要。

以下是大模型目前不能够或者不擅长做的一些事情：

- 精确的数学计算：在复杂或高精度计算中可能出错。
- 长期记忆和学习：在单次对话中无法保留或学习新信息。
- 创造性思维：虽能生成内容，但难以产生真正原创的想法或概念。
- 复杂推理和因果关系：在需要深度逻辑推理的任务中可能表现欠佳。
- 道德和伦理判断：难以理解和应用复杂的道德伦理标准。
- 理解上下文细微差别：可能误解复杂的讽刺、幽默或文化特定的表达。
- 实时更新知识：大模型的知识基于训练数据，无法实时获取最新信息。
- 真实世界交互：它们不能直接与物理世界互动，如操作设备或进行实验。
- 处理模糊或不完整信息：在信息不足时可能难以做出准确判断。
- 自我意识和情感：不具备真正的自我意识或情感体验。
- 理解个人经历：无法真正理解或共情人类的个人经历和情感。
- 独立决策：不能在没有人类监督的情况下做出重要决策。
- 处理极度专业或小众领域：在非常专业或罕见的领域知识可能不足。
- 长期规划和战略思考：难以进行复杂的长期策略制定。

认识这些局限性有助于我们更好地利用大模型，并在适当的场景下结合人类专业知识和判断力。

我们在使用大模型时要时刻清楚：它们不能代替人类的智慧、创造力和复杂的决策能力。随着技术的不断进步，我们可以期待大模型在未来取得更多的进展，但目前它们的局限性仍需被认真对待。


## 4. 大模型概览

### 4.1 国内外大模型

大模型发展至今，已经不胜枚举，他们的技术栈大体都很相似，其形式基本也多是以聊天对话为主，我们没有必要对他们一一尝试。

下表中列举一些比较有代表性的大模型：

| 名称                                                     | 所属公司               |           是否开源           |
|----------------------------------------------------------|------------------------|:----------------------------:|
| [ChatGPT](https://chatgpt.com/)                          | OpenAI                 |  <font color="red">✗</font>  |
| [Claude](https://claude.ai/)                             | Anthropic              |  <font color="red">✗</font>  |
| [Gemini](https://gemini.google.com/)                     | Google                 |  <font color="red">✗</font>  |
| [Copilot](https://copilot.microsoft.com/)                | Microsoft              |  <font color="red">✗</font>  |
| [Phi3](https://azure.microsoft.com/zh-cn/products/phi-3) | Microsoft              |  <font color="red">✗</font>  |
| [Llama3](https://www.meta.ai/)                           | Meta (Facebook)        | <font color="green">✓</font> |
| [Mixtral](https://mistral.ai/)                           | Mistral AI             | <font color="green">✓</font> |
| [文心一言](https://yiyan.baidu.com/)                     | 百度                   |  <font color="red">✗</font>  |
| [ChatGLM](https://chatglm.cn/)                           | 智谱AI                 | <font color="green">✓</font> |
| [通义千问](https://tongyi.aliyun.com/)                   | 阿里巴巴               | <font color="green">✓</font> |
| [DeepSeek](https://chat.deepseek.com/)                   | 深度求索               | <font color="green">✓</font> |
| [Kimi](https://kimi.moonshot.cn/)                        | 月之暗面 (Moonshot AI) |  <font color="red">✗</font>  |
| [星火](https://xinghuo.xfyun.cn/)                        | 科大讯飞               |  <font color="red">✗</font>  |
| [豆包](https://www.doubao.com/chat/)                     | 字节跳动               |  <font color="red">✗</font>  |
| [百川](https://www.baichuan-ai.com/)                     | 百川智能               | <font color="green">✓</font> |
| [元宝](https://yuanbao.tencent.com/)                     | 腾讯                   | <font color="green">✓</font> |
| [万知](https://www.wanzhi.com/)                          | 零一万物               | <font color="green">✓</font> |
| [海螺 AI](https://hailuoai.com/)                         | MiniMax                |  <font color="red">✗</font>  |

在大模型领域，OpenAI 的 GPT 系列无疑占据着举足轻重的地位，每一次新版本的发布都能吸引行业内的广泛关注，并 数次引领人工智能发展的新趋势。

Claude、Gemini (Bard)、Copilot (Bing Chat) 等模型在早期便已崭露头角，但 Meta 的 Llama 系列因开源的特性，在开发者社区中占据着独特的地位。不仅有很多机构和企业以 Llama3 为基座开发出了自己的大模型，而且它还提供仅 80 亿参数的轻量化版本，使得个人用户也能在普通计算机上部署和调试，成为目前最受欢迎的开源大模型之一。

微软开源的 Phi3 模型也很有特点，它是众多模型里唯一的一个小模型。其 Mini 版本仅有 38 亿参数，Medium 版本也就只有 140 亿参数。更令人吃惊的是如此小的参数量却能达到与 GPT-3.5 接近的推理效果。这使得它可以流畅的运行在移动端设备上

在国内，百度的“文心一言”作为先行者，其综合能力稳居行业第一梯队。然而在开发者群体中，反响更大的则是智谱 AI 的 ChatGLM 大模型，它和 Llama3 一样采取了开源策略。

ChatGLM 是由清华大学的 KEG 实验室与智谱 AI 合作开发，紧随“文心一言”之后发布，其推理性能在诸多大语言模型中名列前茅。

另一款值得关注的大模型是月之暗面（Moonshot AI）的 Kimi，它支持超长文本的输入与输出，最大可达 200 万字符，为用户提供了非常不错的交互体验。

此外，DeepSeek 凭借其独特的 MoE 与 MLA 结合的架构设计，实现了在保证模型效能的同时，大幅降低了推理成本。DeepSeek 平台率先将百万 Token 的价格降至 1 元。其 V2 版本发布时，在代码生成能力上更是取得了与 GPT-4 相媲美的成绩。

其他大模型也各有特色，其中不少在新版本发布时，测评结果都达到了全球领先水平，感兴趣的可以点击上面表格中的链接去尝试。

我们后面教程中将要使用的大模型主要是 ChatGPT、Llama3、ChatGLM、Qwen。

### 4.2 大模型价格对比

随着算法的不断优化以及硬件性能的提升，大模型的训练成本和推理成本也不断降低。2024 年 5 月，国内外的大模型经历了一轮史无前例的大降价，有的比原来降低了 90% 多，部分模型甚至直接可以免费使用。

这极大的降低了我们作为普通开发者的使用门槛。下表中是每 100 万 Token 的价格表，数据日期 2024-06-20。

| 厂商      | 模型                  | 上下文长度 | 输入   | 输出   |
|-----------|-----------------------|------------|--------|--------|
| 深度求索  | deepseek-chat         | 32k        | ¥ 1    | ¥ 2    |
|           | deepseek-coder        | 32k        | ¥ 1    | ¥ 2    |
| 智谱清言  | GLM-4-Flash           | 128k       | ¥ 0.1  | ¥ 0.1  |
|           | GLM-4-Air             | 128k       | ¥ 1    | ¥ 1    |
|           | GLM-4-AirX            | 8k         | ¥ 10   | ¥ 10   |
|           | GLM-4V                | 2k         | ¥ 50   | ¥ 50   |
|           | GLM-4-0520            | 128k       | ¥ 100  | ¥ 100  |
| 腾讯      | hunyuan-lite          | 256K       | ¥ 0    | ¥ 0    |
|           | hunyuan-standard      | 32K        | ¥ 4.5  | ¥ 5    |
|           | hunyuan-standard-256k | 256K       | ¥ 15   | ¥ 60   |
|           | hunyuan-pro           | 32K        | ¥ 30   | ¥ 100  |
| 阿里巴巴  | qwen-long             | 1000万     | ¥ 0.5  | ¥ 2    |
|           | qwen-turbo            | 8K         | ¥ 2    | ¥ 6    |
|           | qwen-plus             | 32K        | ¥ 4    | ¥ 12   |
|           | qwen-max              | 8K         | ¥ 40   | ¥ 120  |
| 字节跳动  | Doubao-pro-4k         | 4K         | ¥ 0.8  | ¥ 2    |
|           | Doubao-pro-32k        | 32K        | ¥ 0.8  | ¥ 2    |
|           | Doubao-pro-128k       | 128K       | ¥ 5    | ¥ 9    |
| 月之暗面  | moonshot-v1-8k        | 8K         | ¥ 12   | ¥ 12   |
|           | moonshot-v1-32k       | 32K        | ¥ 24   | ¥ 24   |
|           | moonshot-v1-128k      | 128K       | ¥ 60   | ¥ 60   |
| 百度      | ERNIE-Speed           | 8K、128K   | ¥ 免费 | ¥ 免费 |
|           | ERNIE-Lite            | 8K、128K   | ¥ 免费 | ¥ 免费 |
|           | ERNIE-3.5系列         | 8K         | ¥ 12   | ¥ 12   |
|           | ERNIE-4.0系列         | 8K         | ¥ 120  | ¥ 120  |
| 零一万物  | yi-spark              | 16K        | ¥ 1    | ¥ 1    |
|           | yi-medium             | 16K        | ¥ 2.5  | ¥ 2.5  |
|           | yi-large              | 32K        | ¥ 20   | ¥ 20   |
| OpenAI    | gpt-3.5-turbo-0125    | 16K        | $ 0.5  | $ 1.5  |
|           | gpt-4o                | 128K       | $ 5    | $ 15   |
|           | gpt-4-turbo           | 128K       | $ 10   | $ 30   |
|           | gpt-4                 | 多模态     | $ 30   | $ 60   |
| Google    | Gemini 1.5 Pro        | 128K       | $ 3.5  | $ 10.5 |
|           | Gemini 1.0 Pro        | 32K        | $ 0.5  | $ 1.5  |
| Anthropic | Claude 3 Haiku        | 200K       | $ 0.25 | $ 1.25 |
|           | Claude 3 Sonnet       | 200K       | $ 3    | $ 15   |
|           | Claude 3 Opus         | 200K       | $ 15   | $ 75   |

请注意，以上价格仅供参考，具体价格可能会根据厂商政策和市场情况有所变动。选择合适的大模型时，除了考虑价格因素外，还应该考虑模型的性能、可扩展性、易用性以及社区支持等因素。
